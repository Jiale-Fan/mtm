defaults:
    - datasets: softgym
    - override hydra/launcher: slurm
    - override hydra/output: local
    - _self_

tokenizers:
    states:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
      normalize: True
    # if states are rgb images 
    # states:
    #   _target_: research.mtm.tokenizers.patchify.PatchifyTokenizer.create
    #   patch_size: 16
    #   normalize: True
    actions:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
      normalize: True
    returns:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
      normalize: True

model_config:
    _target_: research.mtm.models.mtm_model.MTMConfig
    norm: "none"
    n_embd: 256
    n_enc_layer: 1
    n_dec_layer: 1
    n_head: 4
    dropout: 0.1
    loss_keys: null
    latent_dim: null

state_only_dataset: null
ckpt_path: /home/jiale/mtm/outputs/mtm_softgym_debug/2024-05-28_14-49-06/saved_models/2024-05-28-14-49-06/model_10000.pt
image_encoder: MLP
shapes:
  MLP:
    # states: [64, 768]
    states: [1, 33]
    actions: [1, 4]
    returns: [1, 1]
    # rewards: [1, 4, 1]
    

args:
    _target_: research.mtm.train.RunConfig
    seed: 0
    batch_size: 64
    n_workers: 10
    traj_length: 4

    ### Debug
    # log_every: 1
    # print_every: 1
    # eval_every: 1
    # save_every: 1

    device: cuda
    mask_ratios: [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1.0] # ??
    mask_patterns: ["FD"]
    warmup_steps: 10 # !!!!! 
    num_train_steps: 100 # !!!!!
    learning_rate: 0.0001
    weight_decay:  0.005
    mode_weights: [0.2, 0.1, 0.7] # ??
    tsp_ratio: 1



env_args:
  env: RopeFlatten
  symbolic: False
  seed: 0
  max_episode_length: 200
  action_repeat: 1
  bit_depth: 8
  image_dim: 128
  env_kwargs:
    observation_mode: cam_rgb
    action_mode: picker
    num_picker: 1
    render: True
    headless: False
    horizon: 75
    action_repeat: 8
    render_mode: cloth
    num_variations: 80
    use_cached_states: True
    deterministic: False
  normalize_observation: True
  scale_reward: 50.0
  clip_obs: null # 


#   reward_scales = {
#     'PassWater': 20.0,
#     'PourWater': 20.0,
#     'ClothFold': 50.0,
#     'ClothFlatten': 50.0,
#     'ClothDrop': 50.0,
#     'RopeFlatten': 50.0,
# }

# clip_obs = {
#     'PassWater': None,
#     'PourWater': None,
#     'ClothFold': (-3, 3),
#     'ClothFlatten': (-2, 2),
#     'ClothDrop': None,
#     'RopeFlatten': None,
# }


wandb:
  project: MTM_softgym
  entity: ""
  resume: null
  # resume: allow

job_name: job

hydra:
    job:
        name: mtm_softgym_debug
        chdir: True
